2018-12-10 21:37:50,218 - Model run on GPU
2018-12-10 21:37:54,280 - Model initialized on GPU
2018-12-10 21:37:54,281 - TopicalWordEmbedding
2018-12-10 21:37:54,282 - {'batch_size': 2048, 'epochs': 100, 'learning_rate': 0.0005, 'lr_decay': 0.9, 'weight_decay': 0.0001, 'model': 'TopicalWordEmbedding', 'on_cuda': True}
2018-12-10 21:43:24,044 - TRAIN	epoch: 0/100	batch: 199/2067	loss: 181267.138281
2018-12-10 21:48:48,642 - TRAIN	epoch: 0/100	batch: 399/2067	loss: 165508.247148
2018-12-10 21:54:11,787 - TRAIN	epoch: 0/100	batch: 599/2067	loss: 158461.614193
2018-12-10 21:59:39,163 - TRAIN	epoch: 0/100	batch: 799/2067	loss: 154435.532305
2018-12-10 22:04:57,706 - TRAIN	epoch: 0/100	batch: 999/2067	loss: 151500.627859
2018-12-10 22:10:24,365 - TRAIN	epoch: 0/100	batch: 1199/2067	loss: 149233.938587
2018-12-10 22:15:58,284 - TRAIN	epoch: 0/100	batch: 1399/2067	loss: 147443.702232
2018-12-10 22:21:25,488 - TRAIN	epoch: 0/100	batch: 1599/2067	loss: 145893.381909
2018-12-10 22:26:51,328 - TRAIN	epoch: 0/100	batch: 1799/2067	loss: 144567.132205
2018-12-10 22:32:31,405 - TRAIN	epoch: 0/100	batch: 1999/2067	loss: 143475.011652
2018-12-10 22:34:17,337 - epoch: 0/100	average_loss: 143139.647088
2018-12-10 22:34:17,439 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-10 22:34:17,439 - learning_rate changed to 0.000450
2018-12-10 22:39:50,748 - TRAIN	epoch: 1/100	batch: 199/2067	loss: 132504.747539
2018-12-10 22:45:32,940 - TRAIN	epoch: 1/100	batch: 399/2067	loss: 132410.951738
2018-12-10 22:52:15,904 - TRAIN	epoch: 1/100	batch: 599/2067	loss: 132102.902448
2018-12-10 22:58:56,010 - TRAIN	epoch: 1/100	batch: 799/2067	loss: 131956.959355
2018-12-10 23:05:19,759 - TRAIN	epoch: 1/100	batch: 999/2067	loss: 131795.735211
2018-12-10 23:10:39,557 - TRAIN	epoch: 1/100	batch: 1199/2067	loss: 131642.736712
2018-12-10 23:15:59,289 - TRAIN	epoch: 1/100	batch: 1399/2067	loss: 131540.458471
2018-12-10 23:21:14,562 - TRAIN	epoch: 1/100	batch: 1599/2067	loss: 131427.518682
2018-12-10 23:26:40,219 - TRAIN	epoch: 1/100	batch: 1799/2067	loss: 131300.654392
2018-12-10 23:32:07,874 - TRAIN	epoch: 1/100	batch: 1999/2067	loss: 131221.330023
2018-12-10 23:33:52,617 - epoch: 1/100	average_loss: 131189.515345
2018-12-10 23:33:52,642 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-10 23:33:52,644 - learning_rate changed to 0.000405
2018-12-10 23:39:13,232 - TRAIN	epoch: 2/100	batch: 199/2067	loss: 130285.433672
2018-12-10 23:44:35,016 - TRAIN	epoch: 2/100	batch: 399/2067	loss: 130204.678438
2018-12-10 23:50:02,642 - TRAIN	epoch: 2/100	batch: 599/2067	loss: 130066.994427
2018-12-10 23:55:22,814 - TRAIN	epoch: 2/100	batch: 799/2067	loss: 129999.047178
2018-12-11 00:00:50,717 - TRAIN	epoch: 2/100	batch: 999/2067	loss: 130011.841930
2018-12-11 00:06:23,081 - TRAIN	epoch: 2/100	batch: 1199/2067	loss: 129972.208262
2018-12-11 00:11:41,422 - TRAIN	epoch: 2/100	batch: 1399/2067	loss: 129932.613309
2018-12-11 00:16:59,754 - TRAIN	epoch: 2/100	batch: 1599/2067	loss: 129863.723540
2018-12-11 00:22:19,749 - TRAIN	epoch: 2/100	batch: 1799/2067	loss: 129818.894340
2018-12-11 00:27:32,177 - TRAIN	epoch: 2/100	batch: 1999/2067	loss: 129794.157945
2018-12-11 00:29:15,301 - epoch: 2/100	average_loss: 129783.897292
2018-12-11 00:29:15,330 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-11 00:29:15,330 - learning_rate changed to 0.000365
2018-12-11 00:34:29,364 - TRAIN	epoch: 3/100	batch: 199/2067	loss: 129579.289297
2018-12-11 00:39:47,181 - TRAIN	epoch: 3/100	batch: 399/2067	loss: 129455.404062
2018-12-11 00:44:56,574 - TRAIN	epoch: 3/100	batch: 599/2067	loss: 129352.177721
2018-12-11 00:50:23,731 - TRAIN	epoch: 3/100	batch: 799/2067	loss: 129325.096221
2018-12-11 00:56:05,416 - TRAIN	epoch: 3/100	batch: 999/2067	loss: 129324.087062
2018-12-11 01:01:45,404 - TRAIN	epoch: 3/100	batch: 1199/2067	loss: 129289.942988
2018-12-11 01:07:23,292 - TRAIN	epoch: 3/100	batch: 1399/2067	loss: 129247.026948
2018-12-11 01:13:01,647 - TRAIN	epoch: 3/100	batch: 1599/2067	loss: 129214.333066
2018-12-11 01:18:45,876 - TRAIN	epoch: 3/100	batch: 1799/2067	loss: 129182.644453
2018-12-11 01:24:29,618 - TRAIN	epoch: 3/100	batch: 1999/2067	loss: 129189.619324
2018-12-11 01:26:20,274 - epoch: 3/100	average_loss: 129188.590853
2018-12-11 01:26:20,304 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-11 01:26:20,304 - learning_rate changed to 0.000328
2018-12-11 01:32:10,238 - TRAIN	epoch: 4/100	batch: 199/2067	loss: 129234.753555
2018-12-11 01:37:57,293 - TRAIN	epoch: 4/100	batch: 399/2067	loss: 129115.739629
2018-12-11 01:43:48,988 - TRAIN	epoch: 4/100	batch: 599/2067	loss: 128920.316211
2018-12-11 01:49:45,406 - TRAIN	epoch: 4/100	batch: 799/2067	loss: 128922.888203
2018-12-11 01:55:41,033 - TRAIN	epoch: 4/100	batch: 999/2067	loss: 128935.780289
2018-12-11 02:01:41,160 - TRAIN	epoch: 4/100	batch: 1199/2067	loss: 128926.410579
2018-12-11 02:07:28,037 - TRAIN	epoch: 4/100	batch: 1399/2067	loss: 128879.309715
2018-12-11 02:13:14,543 - TRAIN	epoch: 4/100	batch: 1599/2067	loss: 128871.798477
2018-12-11 02:18:56,395 - TRAIN	epoch: 4/100	batch: 1799/2067	loss: 128826.763997
2018-12-11 02:24:44,478 - TRAIN	epoch: 4/100	batch: 1999/2067	loss: 128815.202160
2018-12-11 02:26:28,582 - epoch: 4/100	average_loss: 128830.221949
2018-12-11 02:26:28,616 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-11 02:26:28,616 - learning_rate changed to 0.000295
2018-12-11 02:32:25,352 - TRAIN	epoch: 5/100	batch: 199/2067	loss: 128700.886758
2018-12-11 02:38:15,276 - TRAIN	epoch: 5/100	batch: 399/2067	loss: 128628.655293
2018-12-11 02:44:03,184 - TRAIN	epoch: 5/100	batch: 599/2067	loss: 128538.263893
2018-12-11 02:49:58,018 - TRAIN	epoch: 5/100	batch: 799/2067	loss: 128527.370537
2018-12-11 02:55:41,354 - TRAIN	epoch: 5/100	batch: 999/2067	loss: 128573.489688
2018-12-11 03:01:37,571 - TRAIN	epoch: 5/100	batch: 1199/2067	loss: 128538.497064
2018-12-11 03:07:27,597 - TRAIN	epoch: 5/100	batch: 1399/2067	loss: 128530.569336
2018-12-11 03:13:19,820 - TRAIN	epoch: 5/100	batch: 1599/2067	loss: 128536.927622
2018-12-11 03:19:09,496 - TRAIN	epoch: 5/100	batch: 1799/2067	loss: 128498.436892
2018-12-11 03:24:55,784 - TRAIN	epoch: 5/100	batch: 1999/2067	loss: 128510.346793
2018-12-11 03:26:53,217 - epoch: 5/100	average_loss: 128519.728370
2018-12-11 03:26:53,257 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-11 03:26:53,258 - learning_rate changed to 0.000266
2018-12-11 03:32:40,271 - TRAIN	epoch: 6/100	batch: 199/2067	loss: 128256.212656
2018-12-11 03:38:19,682 - TRAIN	epoch: 6/100	batch: 399/2067	loss: 128364.939102
2018-12-11 03:43:55,915 - TRAIN	epoch: 6/100	batch: 599/2067	loss: 128309.378646
2018-12-11 03:49:40,482 - TRAIN	epoch: 6/100	batch: 799/2067	loss: 128387.028789
2018-12-11 03:55:27,431 - TRAIN	epoch: 6/100	batch: 999/2067	loss: 128395.896422
2018-12-11 04:01:13,491 - TRAIN	epoch: 6/100	batch: 1199/2067	loss: 128387.262962
2018-12-11 04:07:01,494 - TRAIN	epoch: 6/100	batch: 1399/2067	loss: 128334.431283
2018-12-11 04:12:44,967 - TRAIN	epoch: 6/100	batch: 1599/2067	loss: 128320.917891
2018-12-11 04:18:32,241 - TRAIN	epoch: 6/100	batch: 1799/2067	loss: 128303.555799
2018-12-11 04:24:26,088 - TRAIN	epoch: 6/100	batch: 1999/2067	loss: 128325.571172
2018-12-11 04:26:22,694 - epoch: 6/100	average_loss: 128337.519433
2018-12-11 04:26:22,727 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-11 04:26:22,728 - learning_rate changed to 0.000239
2018-12-11 04:32:19,877 - TRAIN	epoch: 7/100	batch: 199/2067	loss: 128220.960117
2018-12-11 04:38:13,139 - TRAIN	epoch: 7/100	batch: 399/2067	loss: 128097.731016
2018-12-11 04:44:02,459 - TRAIN	epoch: 7/100	batch: 599/2067	loss: 128141.834063
2018-12-11 04:49:54,692 - TRAIN	epoch: 7/100	batch: 799/2067	loss: 128156.870449
2018-12-11 04:55:58,692 - TRAIN	epoch: 7/100	batch: 999/2067	loss: 128144.880125
2018-12-11 05:01:47,995 - TRAIN	epoch: 7/100	batch: 1199/2067	loss: 128148.913607
2018-12-11 05:07:40,792 - TRAIN	epoch: 7/100	batch: 1399/2067	loss: 128141.107227
2018-12-11 05:13:35,631 - TRAIN	epoch: 7/100	batch: 1599/2067	loss: 128142.389385
2018-12-11 05:19:38,084 - TRAIN	epoch: 7/100	batch: 1799/2067	loss: 128100.121727
2018-12-11 05:25:34,574 - TRAIN	epoch: 7/100	batch: 1999/2067	loss: 128117.508867
2018-12-11 05:27:29,519 - epoch: 7/100	average_loss: 128121.241719
2018-12-11 05:27:29,548 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-11 05:27:29,548 - learning_rate changed to 0.000215
2018-12-11 05:33:14,377 - TRAIN	epoch: 8/100	batch: 199/2067	loss: 127967.554141
2018-12-11 05:39:12,920 - TRAIN	epoch: 8/100	batch: 399/2067	loss: 128072.821035
2018-12-11 05:45:03,995 - TRAIN	epoch: 8/100	batch: 599/2067	loss: 128000.784609
2018-12-11 05:50:46,758 - TRAIN	epoch: 8/100	batch: 799/2067	loss: 128052.983643
2018-12-11 05:56:52,591 - TRAIN	epoch: 8/100	batch: 999/2067	loss: 128062.470734
2018-12-11 06:02:48,472 - TRAIN	epoch: 8/100	batch: 1199/2067	loss: 128033.020254
2018-12-11 06:08:36,652 - TRAIN	epoch: 8/100	batch: 1399/2067	loss: 128046.816987
2018-12-11 06:14:13,487 - TRAIN	epoch: 8/100	batch: 1599/2067	loss: 128004.400728
2018-12-11 06:20:11,671 - TRAIN	epoch: 8/100	batch: 1799/2067	loss: 127990.103207
2018-12-11 06:26:01,749 - TRAIN	epoch: 8/100	batch: 1999/2067	loss: 127986.527930
2018-12-11 06:27:59,913 - epoch: 8/100	average_loss: 127995.986965
2018-12-11 06:27:59,946 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-11 06:27:59,946 - learning_rate changed to 0.000194
2018-12-11 06:33:51,550 - TRAIN	epoch: 9/100	batch: 199/2067	loss: 128008.396211
2018-12-11 06:39:42,874 - TRAIN	epoch: 9/100	batch: 399/2067	loss: 128061.216191
2018-12-11 06:45:49,537 - TRAIN	epoch: 9/100	batch: 599/2067	loss: 127877.621745
2018-12-11 06:51:34,666 - TRAIN	epoch: 9/100	batch: 799/2067	loss: 127885.067549
2018-12-11 06:57:24,579 - TRAIN	epoch: 9/100	batch: 999/2067	loss: 127913.992883
2018-12-11 07:03:23,549 - TRAIN	epoch: 9/100	batch: 1199/2067	loss: 127894.958053
2018-12-11 07:09:11,446 - TRAIN	epoch: 9/100	batch: 1399/2067	loss: 127883.388739
2018-12-11 07:15:01,646 - TRAIN	epoch: 9/100	batch: 1599/2067	loss: 127910.853037
2018-12-11 07:20:54,814 - TRAIN	epoch: 9/100	batch: 1799/2067	loss: 127874.880456
2018-12-11 07:26:53,639 - TRAIN	epoch: 9/100	batch: 1999/2067	loss: 127882.557402
2018-12-11 07:28:52,199 - epoch: 9/100	average_loss: 127887.842029
2018-12-11 07:28:52,235 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-11 07:28:52,236 - learning_rate changed to 0.000174
2018-12-11 07:34:53,111 - TRAIN	epoch: 10/100	batch: 199/2067	loss: 127709.282969
2018-12-11 07:40:41,771 - TRAIN	epoch: 10/100	batch: 399/2067	loss: 127789.930391
2018-12-11 07:46:48,812 - TRAIN	epoch: 10/100	batch: 599/2067	loss: 127737.922930
2018-12-11 07:52:48,478 - TRAIN	epoch: 10/100	batch: 799/2067	loss: 127748.232031
2018-12-11 07:58:44,327 - TRAIN	epoch: 10/100	batch: 999/2067	loss: 127780.511461
2018-12-11 08:04:52,028 - TRAIN	epoch: 10/100	batch: 1199/2067	loss: 127803.728789
2018-12-11 08:10:57,829 - TRAIN	epoch: 10/100	batch: 1399/2067	loss: 127795.146713
2018-12-11 08:16:52,461 - TRAIN	epoch: 10/100	batch: 1599/2067	loss: 127816.274038
2018-12-11 08:22:44,208 - TRAIN	epoch: 10/100	batch: 1799/2067	loss: 127781.108207
2018-12-11 08:28:39,264 - TRAIN	epoch: 10/100	batch: 1999/2067	loss: 127791.628695
2018-12-11 08:30:37,532 - epoch: 10/100	average_loss: 127783.902019
2018-12-11 08:30:37,571 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-11 08:30:37,572 - learning_rate changed to 0.000157
2018-12-11 08:36:36,757 - TRAIN	epoch: 11/100	batch: 199/2067	loss: 127726.091406
2018-12-11 08:42:25,425 - TRAIN	epoch: 11/100	batch: 399/2067	loss: 127855.892910
2018-12-11 08:48:22,393 - TRAIN	epoch: 11/100	batch: 599/2067	loss: 127680.777513
2018-12-11 08:54:20,042 - TRAIN	epoch: 11/100	batch: 799/2067	loss: 127654.052471
2018-12-11 09:00:10,534 - TRAIN	epoch: 11/100	batch: 999/2067	loss: 127720.151586
2018-12-11 09:06:07,189 - TRAIN	epoch: 11/100	batch: 1199/2067	loss: 127716.559141
2018-12-11 09:12:09,786 - TRAIN	epoch: 11/100	batch: 1399/2067	loss: 127724.218153
2018-12-11 09:17:19,661 - TRAIN	epoch: 11/100	batch: 1599/2067	loss: 127686.295938
2018-12-11 09:22:14,803 - TRAIN	epoch: 11/100	batch: 1799/2067	loss: 127676.066150
2018-12-11 09:27:13,715 - TRAIN	epoch: 11/100	batch: 1999/2067	loss: 127671.153027
2018-12-11 09:28:54,229 - epoch: 11/100	average_loss: 127676.983464
2018-12-11 09:28:54,270 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-11 09:28:54,270 - learning_rate changed to 0.000141
2018-12-11 09:33:52,906 - TRAIN	epoch: 12/100	batch: 199/2067	loss: 127577.445977
2018-12-11 09:38:54,997 - TRAIN	epoch: 12/100	batch: 399/2067	loss: 127660.800527
2018-12-11 09:43:48,242 - TRAIN	epoch: 12/100	batch: 599/2067	loss: 127534.145299
2018-12-11 09:48:46,834 - TRAIN	epoch: 12/100	batch: 799/2067	loss: 127605.189014
2018-12-11 09:53:42,470 - TRAIN	epoch: 12/100	batch: 999/2067	loss: 127659.396422
2018-12-11 09:58:39,678 - TRAIN	epoch: 12/100	batch: 1199/2067	loss: 127636.488887
2018-12-11 10:03:35,417 - TRAIN	epoch: 12/100	batch: 1399/2067	loss: 127647.163136
2018-12-11 10:08:31,720 - TRAIN	epoch: 12/100	batch: 1599/2067	loss: 127621.701030
2018-12-11 10:13:30,042 - TRAIN	epoch: 12/100	batch: 1799/2067	loss: 127620.207556
2018-12-11 10:18:26,057 - TRAIN	epoch: 12/100	batch: 1999/2067	loss: 127608.972137
2018-12-11 10:19:59,716 - epoch: 12/100	average_loss: 127614.066081
2018-12-11 10:19:59,739 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-11 10:19:59,740 - learning_rate changed to 0.000127
2018-12-11 10:24:50,638 - TRAIN	epoch: 13/100	batch: 199/2067	loss: 127760.528398
2018-12-11 10:29:50,449 - TRAIN	epoch: 13/100	batch: 399/2067	loss: 127620.681953
2018-12-11 10:34:48,375 - TRAIN	epoch: 13/100	batch: 599/2067	loss: 127554.622396
2018-12-11 10:39:35,989 - TRAIN	epoch: 13/100	batch: 799/2067	loss: 127550.695205
2018-12-11 10:44:50,336 - TRAIN	epoch: 13/100	batch: 999/2067	loss: 127538.785312
2018-12-11 10:50:22,308 - TRAIN	epoch: 13/100	batch: 1199/2067	loss: 127507.278835
2018-12-11 10:55:49,193 - TRAIN	epoch: 13/100	batch: 1399/2067	loss: 127552.919704
2018-12-11 11:01:11,113 - TRAIN	epoch: 13/100	batch: 1599/2067	loss: 127528.777061
2018-12-11 11:06:09,302 - TRAIN	epoch: 13/100	batch: 1799/2067	loss: 127492.430990
2018-12-11 11:11:15,245 - TRAIN	epoch: 13/100	batch: 1999/2067	loss: 127506.403266
2018-12-11 11:12:55,359 - epoch: 13/100	average_loss: 127520.570725
2018-12-11 11:12:55,390 - model saved to /data/zlx/topical_wordvec_models/save/32/model
2018-12-11 11:12:55,390 - learning_rate changed to 0.000114
